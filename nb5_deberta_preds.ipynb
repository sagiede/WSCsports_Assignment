{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSC Project - Data Analysis & NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "\n",
    "# Data science imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP imports\n",
    "from transformers import pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = list(set(pd.read_csv(\"data/actions.csv\")[\"parameter\"]))\n",
    "transcripts_folds_df = pd.read_csv('data/transcripts_folds.csv')\n",
    "transcripts_folds_df = transcripts_folds_df.rename(columns={'Text': 'transcript_text'})\n",
    "transcripts_df = transcripts_df[['sample_id', 'transcript_text', 'events']]\n",
    "# transcripts_df['events_str'] = ['Events: ' + ', '.join(l) for l in [[] if l == '[None]' else eval(l) for l in transcripts_df['events'].tolist()]]\n",
    "# transcripts_df['events_and_transcript'] = transcripts_df['events_str'] + '\\n Transcript: ' + transcripts_df['transcript_text']\n",
    "transcripts_text = transcripts_df['transcript_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zero-shot predict actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "filename = 'data/all_df_preds_{MODEL}.json'\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=MODEL, device=-1)\n",
    "\n",
    "batch_size = 16 # or any batch size you prefer\n",
    "actions_preds_all = []\n",
    "for i in tqdm(range(0, len(transcripts_text), batch_size)):\n",
    "    batch = transcripts_text[i:i+batch_size]\n",
    "    actions_preds_all.extend(classifier(batch, ACTIONS, multi_label=False))\n",
    "\n",
    "\n",
    "# Convert the list to a dict, using index as key\n",
    "actions_preds_val_dict = {i: v for i, v in enumerate(actions_preds_all)}\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(actions_preds_val_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zero-shot predict validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>transcript_text</th>\n",
       "      <th>Label</th>\n",
       "      <th>actions_pseudo_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>If you go into that defensive circle and post ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['post up']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>He's double teamed.</td>\n",
       "      <td>1</td>\n",
       "      <td>['double team']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jordan trying to post up against Oxymora.</td>\n",
       "      <td>1</td>\n",
       "      <td>['post up']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>They're going to come and help on all of his p...</td>\n",
       "      <td>0</td>\n",
       "      <td>['post up']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>They're going to come and help on all of his p...</td>\n",
       "      <td>0</td>\n",
       "      <td>['post up']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1101</td>\n",
       "      <td>John Collins can't convert the lob inside.</td>\n",
       "      <td>1</td>\n",
       "      <td>['lob']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>1102</td>\n",
       "      <td>Backdoor cut watch couldn't find him.</td>\n",
       "      <td>0</td>\n",
       "      <td>['backdoor']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1103</td>\n",
       "      <td>Fake getting up in the air and complete the play.</td>\n",
       "      <td>1</td>\n",
       "      <td>['fake']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1104</td>\n",
       "      <td>Here's Porter with a fake.</td>\n",
       "      <td>1</td>\n",
       "      <td>['fake']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1105</td>\n",
       "      <td>Little step back into Lane for two.</td>\n",
       "      <td>1</td>\n",
       "      <td>['step back']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample_id                                    transcript_text  Label  \\\n",
       "0             1  If you go into that defensive circle and post ...      1   \n",
       "1             2                                He's double teamed.      1   \n",
       "2             3          Jordan trying to post up against Oxymora.      1   \n",
       "3             4  They're going to come and help on all of his p...      0   \n",
       "4             5  They're going to come and help on all of his p...      0   \n",
       "...         ...                                                ...    ...   \n",
       "1100       1101         John Collins can't convert the lob inside.      1   \n",
       "1101       1102              Backdoor cut watch couldn't find him.      0   \n",
       "1102       1103  Fake getting up in the air and complete the play.      1   \n",
       "1103       1104                         Here's Porter with a fake.      1   \n",
       "1104       1105                Little step back into Lane for two.      1   \n",
       "\n",
       "     actions_pseudo_label  \n",
       "0             ['post up']  \n",
       "1         ['double team']  \n",
       "2             ['post up']  \n",
       "3             ['post up']  \n",
       "4             ['post up']  \n",
       "...                   ...  \n",
       "1100              ['lob']  \n",
       "1101         ['backdoor']  \n",
       "1102             ['fake']  \n",
       "1103             ['fake']  \n",
       "1104        ['step back']  \n",
       "\n",
       "[1068 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_df = pd.read_csv(\"data/pseudo_actions_labels_with_id.csv\")[['sample_id', 'action_detected']]\n",
    "transcripts_folds_df[['sample_id', 'transcript_text', 'Label']]\n",
    "expr_df = pseudo_df.merge(transcripts_folds_df, on='sample_id', how='inner').rename(columns={'action_detected': 'actions_pseudo_label', 'Text': 'transcript_text'})\n",
    "expr_df = expr_df[['sample_id', 'transcript_text', 'Label', 'actions_pseudo_label']]\n",
    "expr_df = expr_df[expr_df['actions_pseudo_label'].apply(lambda x: len(eval(x)) == 1)]\n",
    "expr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_text = expr_df['transcript_text'].tolist()\n",
    "action_in_transcript = expr_df['actions_pseudo_label'].apply(lambda x: eval(x)[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts_text[:6]\n",
    "# dict(list(zip(transcripts_text, y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The fake action happened during the event\n",
      "{'entailment': 0.3, 'neutral': 99.5, 'contradiction': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "# model_name = \"BAAI/bge-large-en-v1.5 \"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "premise =   'Commentary: So he is doing the fake '\n",
    "# premise =  \"transcript: He's double teamed.\"\n",
    "# hypothesis = \"The movie was good.\"\n",
    "H_pos = '\"The {} action happened during the event'\n",
    "# H_past = '\"The \\\"{}\\\" happened before the event described by the transcript.'\n",
    "# H_hypo = '\"The \\\"{}\\\" was mentioned, but didnt actually happened in the event described by the transcript.'\n",
    "\n",
    "action = \"fake\"\n",
    "hypothesis = H_pos.format(action)\n",
    "print(hypothesis)\n",
    "# hypothesis = H_past.format(action)\n",
    "# hypothesis = H_hypo.format(action)\n",
    "\n",
    "input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "output = model(input[\"input_ids\"])  # device = \"cuda:0\" or \"cpu\"\n",
    "prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068\n",
      "0 (0.0%)\n",
      "64 (6.0%)\n",
      "128 (12.0%)\n",
      "192 (18.0%)\n",
      "256 (24.0%)\n",
      "320 (30.0%)\n",
      "384 (36.0%)\n",
      "448 (41.9%)\n",
      "512 (47.9%)\n",
      "576 (53.9%)\n",
      "640 (59.9%)\n",
      "704 (65.9%)\n",
      "768 (71.9%)\n",
      "832 (77.9%)\n",
      "896 (83.9%)\n",
      "960 (89.9%)\n",
      "1024 (95.9%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9206714034080505,\n",
       " 0.36308109760284424,\n",
       " 0.46421268582344055,\n",
       " 0.07432728260755539,\n",
       " 0.07432728260755539,\n",
       " 0.42258113622665405,\n",
       " 0.03489924222230911,\n",
       " 0.3672965466976166,\n",
       " 0.4331930875778198,\n",
       " 0.8134548664093018,\n",
       " 0.9873661994934082,\n",
       " 0.9557252526283264,\n",
       " 0.9557252526283264,\n",
       " 0.6110960245132446,\n",
       " 0.31805989146232605,\n",
       " 0.8807279467582703,\n",
       " 0.5511886477470398,\n",
       " 0.8708033561706543,\n",
       " 0.7164894342422485,\n",
       " 0.8526604175567627,\n",
       " 0.9619984030723572,\n",
       " 0.22297416627407074,\n",
       " 0.09502753615379333,\n",
       " 0.14371614158153534,\n",
       " 0.3042341470718384,\n",
       " 0.6550674438476562,\n",
       " 0.6293197274208069,\n",
       " 0.7254096269607544,\n",
       " 0.8107462525367737,\n",
       " 0.8784177899360657,\n",
       " 0.6553992033004761,\n",
       " 0.27079063653945923,\n",
       " 0.7524520754814148,\n",
       " 0.5328037738800049,\n",
       " 0.4075777530670166,\n",
       " 0.6480801105499268,\n",
       " 0.5169299244880676,\n",
       " 0.5536037683486938,\n",
       " 0.4757145643234253,\n",
       " 0.9377665519714355,\n",
       " 0.8038438558578491,\n",
       " 0.1109733060002327,\n",
       " 0.39492639899253845,\n",
       " 0.47027021646499634,\n",
       " 0.47027021646499634,\n",
       " 0.9538576006889343,\n",
       " 0.08482426404953003,\n",
       " 0.9614699482917786,\n",
       " 0.7505553364753723,\n",
       " 0.48842862248420715,\n",
       " 0.8249638676643372,\n",
       " 0.5200002789497375,\n",
       " 0.8423528671264648,\n",
       " 0.9751801490783691,\n",
       " 0.5102515816688538,\n",
       " 0.7061624526977539,\n",
       " 0.43240246176719666,\n",
       " 0.5648842453956604,\n",
       " 0.5648841857910156,\n",
       " 0.5648842453956604,\n",
       " 0.5648841857910156,\n",
       " 0.13393203914165497,\n",
       " 0.5691727995872498,\n",
       " 0.9634513258934021,\n",
       " 0.1731499880552292,\n",
       " 0.0710182785987854,\n",
       " 0.1885516494512558,\n",
       " 0.1359158754348755,\n",
       " 0.8738406300544739,\n",
       " 0.25590217113494873,\n",
       " 0.2948012053966522,\n",
       " 0.44438520073890686,\n",
       " 0.7811890244483948,\n",
       " 0.2450755387544632,\n",
       " 0.31391552090644836,\n",
       " 0.42887067794799805,\n",
       " 0.10935213416814804,\n",
       " 0.49537909030914307,\n",
       " 0.13045057654380798,\n",
       " 0.8170070648193359,\n",
       " 0.2712394595146179,\n",
       " 0.0458032563328743,\n",
       " 0.27595242857933044,\n",
       " 0.9370481967926025,\n",
       " 0.9227701425552368,\n",
       " 0.9337775111198425,\n",
       " 0.9694997072219849,\n",
       " 0.48560386896133423,\n",
       " 0.12277219444513321,\n",
       " 0.9204156994819641,\n",
       " 0.06879305094480515,\n",
       " 0.1516699641942978,\n",
       " 0.41167333722114563,\n",
       " 0.12838397920131683,\n",
       " 0.6406541466712952,\n",
       " 0.7884799838066101,\n",
       " 0.9030478000640869,\n",
       " 0.1649581491947174,\n",
       " 0.6762486696243286,\n",
       " 0.9482441544532776,\n",
       " 0.16508817672729492,\n",
       " 0.7008513808250427,\n",
       " 0.7509879469871521,\n",
       " 0.7509879469871521,\n",
       " 0.429415762424469,\n",
       " 0.8418776392936707,\n",
       " 0.5573011040687561,\n",
       " 0.7339988946914673,\n",
       " 0.6508165597915649,\n",
       " 0.7642074227333069,\n",
       " 0.8983467221260071,\n",
       " 0.34975969791412354,\n",
       " 0.8749653697013855,\n",
       " 0.288433313369751,\n",
       " 0.7815874814987183,\n",
       " 0.9753565788269043,\n",
       " 0.9753565788269043,\n",
       " 0.113227479159832,\n",
       " 0.7357409596443176,\n",
       " 0.7455639243125916,\n",
       " 0.9769461750984192,\n",
       " 0.4733496308326721,\n",
       " 0.21006649732589722,\n",
       " 0.08047927916049957,\n",
       " 0.8958330750465393,\n",
       " 0.6126791834831238,\n",
       " 0.843898594379425,\n",
       " 0.8438985347747803,\n",
       " 0.012480347417294979,\n",
       " 0.19172261655330658,\n",
       " 0.2706717848777771,\n",
       " 0.5220184922218323,\n",
       " 0.31350603699684143,\n",
       " 0.581840455532074,\n",
       " 0.9480896592140198,\n",
       " 0.8732450008392334,\n",
       " 0.40849024057388306,\n",
       " 0.8726634979248047,\n",
       " 0.16562584042549133,\n",
       " 0.7465251088142395,\n",
       " 0.3155544698238373,\n",
       " 0.9735506772994995,\n",
       " 0.5061976313591003,\n",
       " 0.4189146161079407,\n",
       " 0.4526345729827881,\n",
       " 0.4880716800689697,\n",
       " 0.9621654748916626,\n",
       " 0.8676988482475281,\n",
       " 0.9602984189987183,\n",
       " 0.7214452624320984,\n",
       " 0.14766423404216766,\n",
       " 0.7793905735015869,\n",
       " 0.37329018115997314,\n",
       " 0.2432427853345871,\n",
       " 0.90872722864151,\n",
       " 0.7255664467811584,\n",
       " 0.8979902267456055,\n",
       " 0.6676940321922302,\n",
       " 0.8785871863365173,\n",
       " 0.3467088043689728,\n",
       " 0.3949967622756958,\n",
       " 0.5120952725410461,\n",
       " 0.2896512448787689,\n",
       " 0.19356347620487213,\n",
       " 0.27745237946510315,\n",
       " 0.27745237946510315,\n",
       " 0.27745237946510315,\n",
       " 0.03420402854681015,\n",
       " 0.09994510561227798,\n",
       " 0.9134858250617981,\n",
       " 0.43182802200317383,\n",
       " 0.5401200652122498,\n",
       " 0.06613433361053467,\n",
       " 0.06613431125879288,\n",
       " 0.24844002723693848,\n",
       " 0.4813820421695709,\n",
       " 0.9804261922836304,\n",
       " 0.4604202210903168,\n",
       " 0.6958868503570557,\n",
       " 0.4328833818435669,\n",
       " 0.4328833520412445,\n",
       " 0.3750761151313782,\n",
       " 0.06033342331647873,\n",
       " 0.7330300807952881,\n",
       " 0.41583043336868286,\n",
       " 0.07894836366176605,\n",
       " 0.6076290011405945,\n",
       " 0.5470637679100037,\n",
       " 0.3912457823753357,\n",
       " 0.24603238701820374,\n",
       " 0.943738579750061,\n",
       " 0.3044106066226959,\n",
       " 0.6579626798629761,\n",
       " 0.5516219139099121,\n",
       " 0.8762080073356628,\n",
       " 0.5801620483398438,\n",
       " 0.580161988735199,\n",
       " 0.5012313723564148,\n",
       " 0.5873271822929382,\n",
       " 0.504945695400238,\n",
       " 0.7053140997886658,\n",
       " 0.6658526062965393,\n",
       " 0.5316530466079712,\n",
       " 0.8441739678382874,\n",
       " 0.4789135754108429,\n",
       " 0.8013967871665955,\n",
       " 0.4518558084964752,\n",
       " 0.9631815552711487,\n",
       " 0.9844387173652649,\n",
       " 0.3178744316101074,\n",
       " 0.20053839683532715,\n",
       " 0.046588364988565445,\n",
       " 0.12158456444740295,\n",
       " 0.9478291273117065,\n",
       " 0.8757206797599792,\n",
       " 0.9589170217514038,\n",
       " 0.5503559708595276,\n",
       " 0.5441074371337891,\n",
       " 0.9761471152305603,\n",
       " 0.7734320163726807,\n",
       " 0.7773982882499695,\n",
       " 0.9061498641967773,\n",
       " 0.8427284955978394,\n",
       " 0.8057343363761902,\n",
       " 0.760137140750885,\n",
       " 0.7178952097892761,\n",
       " 0.8164175748825073,\n",
       " 0.3440677225589752,\n",
       " 0.7471943497657776,\n",
       " 0.3773321211338043,\n",
       " 0.49975812435150146,\n",
       " 0.9586675763130188,\n",
       " 0.6409898400306702,\n",
       " 0.657696545124054,\n",
       " 0.6389030814170837,\n",
       " 0.3322424590587616,\n",
       " 0.807025134563446,\n",
       " 0.2972180247306824,\n",
       " 0.7233320474624634,\n",
       " 0.8255557417869568,\n",
       " 0.8923048377037048,\n",
       " 0.5296812653541565,\n",
       " 0.8639239072799683,\n",
       " 0.7981019616127014,\n",
       " 0.07616693526506424,\n",
       " 0.8328250646591187,\n",
       " 0.4125748872756958,\n",
       " 0.29352518916130066,\n",
       " 0.6567367911338806,\n",
       " 0.09387335926294327,\n",
       " 0.6677099466323853,\n",
       " 0.618380069732666,\n",
       " 0.8030034899711609,\n",
       " 0.9618269205093384,\n",
       " 0.5075879096984863,\n",
       " 0.9061890840530396,\n",
       " 0.5700530409812927,\n",
       " 0.9709975719451904,\n",
       " 0.9709294438362122,\n",
       " 0.8389503359794617,\n",
       " 0.9562028646469116,\n",
       " 0.37910038232803345,\n",
       " 0.0784129798412323,\n",
       " 0.5541956424713135,\n",
       " 0.6722937822341919,\n",
       " 0.8719420433044434,\n",
       " 0.9773226976394653,\n",
       " 0.278270959854126,\n",
       " 0.8517652750015259,\n",
       " 0.2697660028934479,\n",
       " 0.4860036075115204,\n",
       " 0.8996301889419556,\n",
       " 0.9495968818664551,\n",
       " 0.8163708448410034,\n",
       " 0.3836590051651001,\n",
       " 0.11707431823015213,\n",
       " 0.9774860143661499,\n",
       " 0.8073091506958008,\n",
       " 0.2912757098674774,\n",
       " 0.8969050049781799,\n",
       " 0.48597389459609985,\n",
       " 0.61887127161026,\n",
       " 0.9630393385887146,\n",
       " 0.6449134945869446,\n",
       " 0.7866460680961609,\n",
       " 0.47047877311706543,\n",
       " 0.9219514727592468,\n",
       " 0.3117867410182953,\n",
       " 0.8296692967414856,\n",
       " 0.8984264731407166,\n",
       " 0.45685914158821106,\n",
       " 0.5676639676094055,\n",
       " 0.48413845896720886,\n",
       " 0.9486719369888306,\n",
       " 0.42006421089172363,\n",
       " 0.9544415473937988,\n",
       " 0.3257405757904053,\n",
       " 0.406518816947937,\n",
       " 0.30548447370529175,\n",
       " 0.2803287208080292,\n",
       " 0.08792015165090561,\n",
       " 0.3127700388431549,\n",
       " 0.6018468141555786,\n",
       " 0.4616870582103729,\n",
       " 0.2361537367105484,\n",
       " 0.29817333817481995,\n",
       " 0.5142538547515869,\n",
       " 0.8476187586784363,\n",
       " 0.48750433325767517,\n",
       " 0.9400404691696167,\n",
       " 0.11757077276706696,\n",
       " 0.596700131893158,\n",
       " 0.8072251677513123,\n",
       " 0.35450950264930725,\n",
       " 0.47439947724342346,\n",
       " 0.2662755846977234,\n",
       " 0.2591974437236786,\n",
       " 0.711272120475769,\n",
       " 0.8670572638511658,\n",
       " 0.3577623963356018,\n",
       " 0.9154089689254761,\n",
       " 0.8931769728660583,\n",
       " 0.4826586842536926,\n",
       " 0.7005795240402222,\n",
       " 0.5106539726257324,\n",
       " 0.2865549325942993,\n",
       " 0.1490560919046402,\n",
       " 0.09534221142530441,\n",
       " 0.8099410533905029,\n",
       " 0.08756865561008453,\n",
       " 0.9807331562042236,\n",
       " 0.42308637499809265,\n",
       " 0.38520458340644836,\n",
       " 0.7676001787185669,\n",
       " 0.5086696147918701,\n",
       " 0.9915692210197449,\n",
       " 0.016548670828342438,\n",
       " 0.9309675693511963,\n",
       " 0.06541381031274796,\n",
       " 0.5793175101280212,\n",
       " 0.8012882471084595,\n",
       " 0.23020219802856445,\n",
       " 0.7800363302230835,\n",
       " 0.780036211013794,\n",
       " 0.11054444313049316,\n",
       " 0.07327499985694885,\n",
       " 0.8741641044616699,\n",
       " 0.0031533963046967983,\n",
       " 0.7741777896881104,\n",
       " 0.724484920501709,\n",
       " 0.6183682084083557,\n",
       " 0.20355291664600372,\n",
       " 0.5015667080879211,\n",
       " 0.7956531047821045,\n",
       " 0.746267557144165,\n",
       " 0.5147377848625183,\n",
       " 0.35420387983322144,\n",
       " 0.5245974659919739,\n",
       " 0.7600561380386353,\n",
       " 0.5270333290100098,\n",
       " 0.711754322052002,\n",
       " 0.42395302653312683,\n",
       " 0.023876378312706947,\n",
       " 0.0605902262032032,\n",
       " 0.946138322353363,\n",
       " 0.3463537096977234,\n",
       " 0.24171783030033112,\n",
       " 0.44513991475105286,\n",
       " 0.17750845849514008,\n",
       " 0.2627894878387451,\n",
       " 0.4915025532245636,\n",
       " 0.7860733270645142,\n",
       " 0.6981115341186523,\n",
       " 0.83461594581604,\n",
       " 0.890900731086731,\n",
       " 0.40909862518310547,\n",
       " 0.739788830280304,\n",
       " 0.9221640229225159,\n",
       " 0.7250534296035767,\n",
       " 0.5051661133766174,\n",
       " 0.10363159328699112,\n",
       " 0.8396110534667969,\n",
       " 0.9930445551872253,\n",
       " 0.5807718634605408,\n",
       " 0.6524451971054077,\n",
       " 0.7366059422492981,\n",
       " 0.17209802567958832,\n",
       " 0.7189595103263855,\n",
       " 0.5986515283584595,\n",
       " 0.30418887734413147,\n",
       " 0.5157513618469238,\n",
       " 0.5157513618469238,\n",
       " 0.5157513618469238,\n",
       " 0.0024327386636286974,\n",
       " 0.3275878131389618,\n",
       " 0.5082566738128662,\n",
       " 0.3367111384868622,\n",
       " 0.786512553691864,\n",
       " 0.9658715724945068,\n",
       " 0.2866631746292114,\n",
       " 0.4569353759288788,\n",
       " 0.4915026128292084,\n",
       " 0.2626897990703583,\n",
       " 0.373593270778656,\n",
       " 0.5575643181800842,\n",
       " 0.7098181247711182,\n",
       " 0.3855849504470825,\n",
       " 0.6541760563850403,\n",
       " 0.2848404049873352,\n",
       " 0.6827030181884766,\n",
       " 0.7178285717964172,\n",
       " 0.6205078959465027,\n",
       " 0.8231682777404785,\n",
       " 0.42873021960258484,\n",
       " 0.7058358192443848,\n",
       " 0.7184058427810669,\n",
       " 0.19202959537506104,\n",
       " 0.1893843561410904,\n",
       " 0.9283585548400879,\n",
       " 0.6244637966156006,\n",
       " 0.8977369666099548,\n",
       " 0.7722514271736145,\n",
       " 0.053059838712215424,\n",
       " 0.9443627595901489,\n",
       " 0.8443415760993958,\n",
       " 0.8139621019363403,\n",
       " 0.7557736039161682,\n",
       " 0.021754249930381775,\n",
       " 0.11997180432081223,\n",
       " 0.9280956387519836,\n",
       " 0.9280956387519836,\n",
       " 0.00416902918368578,\n",
       " 0.8707989454269409,\n",
       " 0.6792584657669067,\n",
       " 0.019034748896956444,\n",
       " 0.019034748896956444,\n",
       " 0.019034748896956444,\n",
       " 0.019034748896956444,\n",
       " 0.6859918832778931,\n",
       " 0.5057365298271179,\n",
       " 0.7369803786277771,\n",
       " 0.1039351224899292,\n",
       " 0.43716055154800415,\n",
       " 0.5918780565261841,\n",
       " 0.5387827157974243,\n",
       " 0.8936089873313904,\n",
       " 0.0026973793283104897,\n",
       " 0.6840366125106812,\n",
       " 0.049189332872629166,\n",
       " 0.20349161326885223,\n",
       " 0.10892841964960098,\n",
       " 0.8384195566177368,\n",
       " 0.2385634183883667,\n",
       " 0.03623250871896744,\n",
       " 0.3407561182975769,\n",
       " 0.4527161419391632,\n",
       " 0.44903188943862915,\n",
       " 0.5770589113235474,\n",
       " 0.22805120050907135,\n",
       " 0.05008881539106369,\n",
       " 0.402012437582016,\n",
       " 0.23341503739356995,\n",
       " 0.6185510754585266,\n",
       " 0.028150103986263275,\n",
       " 0.5485511422157288,\n",
       " 0.9914714694023132,\n",
       " 0.3235364556312561,\n",
       " 0.6539916396141052,\n",
       " 0.22528833150863647,\n",
       " 0.09392703324556351,\n",
       " 0.3378105163574219,\n",
       " 0.048609644174575806,\n",
       " 0.48013216257095337,\n",
       " 0.33270013332366943,\n",
       " 0.3327001929283142,\n",
       " 0.15474338829517365,\n",
       " 0.26244932413101196,\n",
       " 0.4062189757823944,\n",
       " 0.42056193947792053,\n",
       " 0.1189928948879242,\n",
       " 0.13458454608917236,\n",
       " 0.3029721975326538,\n",
       " 0.6572995185852051,\n",
       " 0.6115756034851074,\n",
       " 0.9209911823272705,\n",
       " 0.1281968504190445,\n",
       " 0.20616479218006134,\n",
       " 0.08208965510129929,\n",
       " 0.014261596836149693,\n",
       " 0.10515554249286652,\n",
       " 0.10317496955394745,\n",
       " 0.9934219717979431,\n",
       " 0.9380871653556824,\n",
       " 0.9812613725662231,\n",
       " 0.483258455991745,\n",
       " 0.3499999940395355,\n",
       " 0.4382404685020447,\n",
       " 0.12427312880754471,\n",
       " 0.03884517028927803,\n",
       " 0.5019873976707458,\n",
       " 0.16909675300121307,\n",
       " 0.39179643988609314,\n",
       " 0.348518967628479,\n",
       " 0.5763434171676636,\n",
       " 0.4481898248195648,\n",
       " 0.15270915627479553,\n",
       " 0.4938007891178131,\n",
       " 0.29835546016693115,\n",
       " 0.836124062538147,\n",
       " 0.8312514424324036,\n",
       " 0.615607738494873,\n",
       " 0.4112831652164459,\n",
       " 0.9907742142677307,\n",
       " 0.3466905355453491,\n",
       " 0.20480826497077942,\n",
       " 0.16721171140670776,\n",
       " 0.25441089272499084,\n",
       " 0.7468248009681702,\n",
       " 0.4757269322872162,\n",
       " 0.9689004421234131,\n",
       " 0.18856914341449738,\n",
       " 0.8343458771705627,\n",
       " 0.859639048576355,\n",
       " 0.5025397539138794,\n",
       " 0.687873899936676,\n",
       " 0.02897738292813301,\n",
       " 0.9262552857398987,\n",
       " 0.34357723593711853,\n",
       " 0.42381423711776733,\n",
       " 0.08151449263095856,\n",
       " 0.8948705792427063,\n",
       " 0.09660714119672775,\n",
       " 0.29935121536254883,\n",
       " 0.1254345029592514,\n",
       " 0.09278961271047592,\n",
       " 0.02762136235833168,\n",
       " 0.8666943311691284,\n",
       " 0.44106221199035645,\n",
       " 0.44106221199035645,\n",
       " 0.34792396426200867,\n",
       " 0.2996310591697693,\n",
       " 0.9352566003799438,\n",
       " 0.8880621790885925,\n",
       " 0.8594966530799866,\n",
       " 0.8349899649620056,\n",
       " 0.8775412440299988,\n",
       " 0.027566127479076385,\n",
       " 0.4173296093940735,\n",
       " 0.635343611240387,\n",
       " 0.8858742117881775,\n",
       " 0.5421990156173706,\n",
       " 0.9738100171089172,\n",
       " 0.6417360901832581,\n",
       " 0.022309208288788795,\n",
       " 0.3417801558971405,\n",
       " 0.7422061562538147,\n",
       " 0.24317339062690735,\n",
       " 0.009304340928792953,\n",
       " 0.8764442205429077,\n",
       " 0.9342807531356812,\n",
       " 0.48198091983795166,\n",
       " 0.592667818069458,\n",
       " 0.19015324115753174,\n",
       " 0.5883399248123169,\n",
       " 0.9193450212478638,\n",
       " 0.0612407848238945,\n",
       " 0.38217753171920776,\n",
       " 0.923601508140564,\n",
       " 0.1931508481502533,\n",
       " 0.786259114742279,\n",
       " 0.9769540429115295,\n",
       " 0.07715560495853424,\n",
       " 0.7204686999320984,\n",
       " 0.9499629735946655,\n",
       " 0.3090103268623352,\n",
       " 0.9858357906341553,\n",
       " 0.1681463122367859,\n",
       " 0.20416536927223206,\n",
       " 0.9171053171157837,\n",
       " 0.8987867832183838,\n",
       " 0.34552592039108276,\n",
       " 0.12059726566076279,\n",
       " 0.9699468016624451,\n",
       " 0.9418476819992065,\n",
       " 0.8256564736366272,\n",
       " 0.7032995820045471,\n",
       " 0.8970772624015808,\n",
       " 0.21567483246326447,\n",
       " 0.9382326006889343,\n",
       " 0.8083941340446472,\n",
       " 0.8756463527679443,\n",
       " 0.4749663174152374,\n",
       " 0.4413142204284668,\n",
       " 0.9288188815116882,\n",
       " 0.17906159162521362,\n",
       " 0.6561284065246582,\n",
       " 0.7130672931671143,\n",
       " 0.8686102628707886,\n",
       " 0.04082437604665756,\n",
       " 0.20279088616371155,\n",
       " 0.530322253704071,\n",
       " 0.1865173727273941,\n",
       " 0.4504912793636322,\n",
       " 0.08683880418539047,\n",
       " 0.7827534079551697,\n",
       " 0.2979423999786377,\n",
       " 0.05811166763305664,\n",
       " 0.9693465828895569,\n",
       " 0.32303398847579956,\n",
       " 0.9292269945144653,\n",
       " 0.5872241258621216,\n",
       " 0.3816031813621521,\n",
       " 0.3043648600578308,\n",
       " 0.580784797668457,\n",
       " 0.9551473259925842,\n",
       " 0.7986171245574951,\n",
       " 0.2573786973953247,\n",
       " 0.48500141501426697,\n",
       " 0.609268307685852,\n",
       " 0.18508891761302948,\n",
       " 0.12422724813222885,\n",
       " 0.6227574348449707,\n",
       " 0.3480991721153259,\n",
       " 0.9808829426765442,\n",
       " 0.5525031089782715,\n",
       " 0.7114931344985962,\n",
       " 0.6777006387710571,\n",
       " 0.48121321201324463,\n",
       " 0.8049519658088684,\n",
       " 0.8101548552513123,\n",
       " 0.19067329168319702,\n",
       " 0.07925239205360413,\n",
       " 0.5320024490356445,\n",
       " 0.5858340263366699,\n",
       " 0.11394177377223969,\n",
       " 0.4142729938030243,\n",
       " 0.5469533205032349,\n",
       " 0.8130549788475037,\n",
       " 0.3472760319709778,\n",
       " 0.7322260141372681,\n",
       " 0.5602028369903564,\n",
       " 0.4657045900821686,\n",
       " 0.5408156514167786,\n",
       " 0.5596544146537781,\n",
       " 0.7554940581321716,\n",
       " 0.7554940581321716,\n",
       " 0.5037018060684204,\n",
       " 0.8897947072982788,\n",
       " 0.382645845413208,\n",
       " 0.6370585560798645,\n",
       " 0.7867130637168884,\n",
       " 0.3049060106277466,\n",
       " 0.4482554495334625,\n",
       " 0.4741327166557312,\n",
       " 0.9461546540260315,\n",
       " 0.4622436761856079,\n",
       " 0.43409091234207153,\n",
       " 0.7392327189445496,\n",
       " 0.635065495967865,\n",
       " 0.7093365788459778,\n",
       " 0.0761246457695961,\n",
       " 0.7647796273231506,\n",
       " 0.6529237031936646,\n",
       " 0.5963608622550964,\n",
       " 0.11714958399534225,\n",
       " 0.26887279748916626,\n",
       " 0.2519839107990265,\n",
       " 0.2519839107990265,\n",
       " 0.2519839107990265,\n",
       " 0.2285734862089157,\n",
       " 0.8270853161811829,\n",
       " 0.38676634430885315,\n",
       " 0.3213409185409546,\n",
       " 0.48582831025123596,\n",
       " 0.4894234240055084,\n",
       " 0.4888080656528473,\n",
       " 0.9508633613586426,\n",
       " 0.9473999738693237,\n",
       " 0.9209255576133728,\n",
       " 0.30736976861953735,\n",
       " 0.9805230498313904,\n",
       " 0.7151756286621094,\n",
       " 0.5388674139976501,\n",
       " 0.826073169708252,\n",
       " 0.41576531529426575,\n",
       " 0.5734255909919739,\n",
       " 0.3721488118171692,\n",
       " 0.24167874455451965,\n",
       " 0.3674983084201813,\n",
       " 0.8697284460067749,\n",
       " 0.4470272362232208,\n",
       " 0.9160324335098267,\n",
       " 0.9325495958328247,\n",
       " 0.29644283652305603,\n",
       " 0.09090045094490051,\n",
       " 0.6534286737442017,\n",
       " 0.4368719756603241,\n",
       " 0.013621718622744083,\n",
       " 0.7456912398338318,\n",
       " 0.37858811020851135,\n",
       " 0.37858811020851135,\n",
       " 0.23069286346435547,\n",
       " 0.5119744539260864,\n",
       " 0.14479587972164154,\n",
       " 0.8671308159828186,\n",
       " 0.8892027735710144,\n",
       " 0.867923378944397,\n",
       " 0.12415854632854462,\n",
       " 0.17546316981315613,\n",
       " 0.29605042934417725,\n",
       " 0.07492709159851074,\n",
       " 0.8124323487281799,\n",
       " 0.0026776085142046213,\n",
       " 0.0026776085142046213,\n",
       " 0.8301796317100525,\n",
       " 0.7824471592903137,\n",
       " 0.5820764899253845,\n",
       " 0.7559385299682617,\n",
       " 0.39935222268104553,\n",
       " 0.9093453288078308,\n",
       " 0.14766986668109894,\n",
       " 0.9364110231399536,\n",
       " 0.28324127197265625,\n",
       " 0.4945710301399231,\n",
       " 0.9383956789970398,\n",
       " 0.4983922243118286,\n",
       " 0.267621785402298,\n",
       " 0.40878239274024963,\n",
       " 0.9178256392478943,\n",
       " 0.7221947908401489,\n",
       " 0.21835751831531525,\n",
       " 0.47060900926589966,\n",
       " 0.36013901233673096,\n",
       " 0.5477263927459717,\n",
       " 0.9518685340881348,\n",
       " 0.2962682247161865,\n",
       " 0.641778290271759,\n",
       " 0.7693875432014465,\n",
       " 0.9472622871398926,\n",
       " 0.717434287071228,\n",
       " 0.717434287071228,\n",
       " 0.35964781045913696,\n",
       " 0.1401287019252777,\n",
       " 0.17607271671295166,\n",
       " 0.9141339659690857,\n",
       " 0.6096972823143005,\n",
       " 0.3590717315673828,\n",
       " 0.3590717017650604,\n",
       " 0.37856948375701904,\n",
       " 0.9511199593544006,\n",
       " 0.015839438885450363,\n",
       " 0.24093182384967804,\n",
       " 0.21615998446941376,\n",
       " 0.5931323766708374,\n",
       " 0.737381100654602,\n",
       " 0.18026795983314514,\n",
       " 0.45333749055862427,\n",
       " 0.44372087717056274,\n",
       " 0.5085564851760864,\n",
       " 0.24228771030902863,\n",
       " 0.24228771030902863,\n",
       " 0.4027166962623596,\n",
       " 0.5225808024406433,\n",
       " 0.508935809135437,\n",
       " 0.38338765501976013,\n",
       " 0.8182024359703064,\n",
       " 0.8182024955749512,\n",
       " 0.8182024955749512,\n",
       " 0.1399242877960205,\n",
       " 0.06781867891550064,\n",
       " 0.418000191450119,\n",
       " 0.5985311269760132,\n",
       " 0.295059472322464,\n",
       " 0.4079343378543854,\n",
       " 0.6299324631690979,\n",
       " 0.8793354034423828,\n",
       " 0.35646504163742065,\n",
       " 0.7968599200248718,\n",
       " 0.7560482621192932,\n",
       " 0.6836155652999878,\n",
       " 0.4057735204696655,\n",
       " 0.5893837809562683,\n",
       " 0.7177086472511292,\n",
       " 0.2437564581632614,\n",
       " 0.4857175052165985,\n",
       " 0.7050575613975525,\n",
       " 0.7050575613975525,\n",
       " 0.7050575613975525,\n",
       " 0.9092379212379456,\n",
       " 0.6750463247299194,\n",
       " 0.41707977652549744,\n",
       " 0.07320936769247055,\n",
       " 0.160697802901268,\n",
       " 0.4430423974990845,\n",
       " 0.29476287961006165,\n",
       " 0.9084059000015259,\n",
       " 0.47414296865463257,\n",
       " 0.14922180771827698,\n",
       " 0.8837071061134338,\n",
       " 0.4325393736362457,\n",
       " 0.9230038523674011,\n",
       " 0.8978155851364136,\n",
       " 0.563537061214447,\n",
       " 0.6344848275184631,\n",
       " 0.11955040693283081,\n",
       " 0.07390426844358444,\n",
       " 0.20974037051200867,\n",
       " 0.012432534247636795,\n",
       " 0.5346211791038513,\n",
       " 0.9616574048995972,\n",
       " 0.8512411713600159,\n",
       " 0.06454982608556747,\n",
       " 0.5266348123550415,\n",
       " 0.9340695738792419,\n",
       " 0.10359175503253937,\n",
       " 0.08434717357158661,\n",
       " 0.14764472842216492,\n",
       " 0.3399637043476105,\n",
       " 0.05649725720286369,\n",
       " 0.4700353145599365,\n",
       " 0.9849432706832886,\n",
       " 0.036274589598178864,\n",
       " 0.9095784425735474,\n",
       " 0.6814833283424377,\n",
       " 0.6124139428138733,\n",
       " 0.9200489521026611,\n",
       " 0.1511419713497162,\n",
       " 0.5843444466590881,\n",
       " 0.8796742558479309,\n",
       " 0.9749592542648315,\n",
       " 0.771300196647644,\n",
       " 0.7891907691955566,\n",
       " 0.13678471744060516,\n",
       " 0.9818850159645081,\n",
       " 0.47712889313697815,\n",
       " 0.32256820797920227,\n",
       " 0.7695813179016113,\n",
       " 0.19123026728630066,\n",
       " 0.9546405673027039,\n",
       " 0.2838425040245056,\n",
       " 0.5990428924560547,\n",
       " 0.622557520866394,\n",
       " 0.46505647897720337,\n",
       " 0.48434072732925415,\n",
       " 0.47576215863227844,\n",
       " 0.29749125242233276,\n",
       " 0.2974912226200104,\n",
       " 0.7492177486419678,\n",
       " 0.6797319650650024,\n",
       " 0.8437363505363464,\n",
       " 0.7223120927810669,\n",
       " 0.4455874264240265,\n",
       " 0.5315035581588745,\n",
       " 0.8635649681091309,\n",
       " 0.33742982149124146,\n",
       " 0.49803733825683594,\n",
       " 0.45416590571403503,\n",
       " 0.28261035680770874,\n",
       " 0.5899884700775146,\n",
       " 0.08184337615966797,\n",
       " 0.2939120829105377,\n",
       " 0.2559035122394562,\n",
       " 0.9597833156585693,\n",
       " 0.8491501212120056,\n",
       " 0.5369554162025452,\n",
       " 0.4455353021621704,\n",
       " 0.9470033645629883,\n",
       " 0.4085429310798645,\n",
       " 0.21339303255081177,\n",
       " 0.6203661561012268,\n",
       " 0.18555641174316406,\n",
       " 0.9613761901855469,\n",
       " 0.41576531529426575,\n",
       " 0.3025418817996979,\n",
       " 0.39165669679641724,\n",
       " 0.9294102787971497,\n",
       " 0.8531522154808044,\n",
       " 0.8531522154808044,\n",
       " 0.0761246457695961,\n",
       " 0.677837610244751,\n",
       " 0.6626779437065125,\n",
       " 0.8398311138153076,\n",
       " 0.7441009283065796,\n",
       " 0.8975589275360107,\n",
       " 0.27058857679367065,\n",
       " 0.6103560924530029,\n",
       " 0.8430050015449524,\n",
       " 0.7026274800300598,\n",
       " 0.17217199504375458,\n",
       " 0.17217199504375458,\n",
       " 0.9850055575370789,\n",
       " 0.4323106110095978,\n",
       " 0.672992467880249,\n",
       " 0.7567691206932068,\n",
       " 0.15514476597309113,\n",
       " 0.12139110267162323,\n",
       " 0.3579058051109314,\n",
       " 0.7413891553878784,\n",
       " 0.6586121320724487,\n",
       " 0.9274504780769348,\n",
       " 0.16958355903625488,\n",
       " 0.8990069627761841,\n",
       " 0.5518594980239868,\n",
       " 0.5906512141227722,\n",
       " 0.4641028642654419,\n",
       " 0.8834182024002075,\n",
       " 0.8834182024002075,\n",
       " 0.9099921584129333,\n",
       " 0.41743025183677673,\n",
       " 0.4110877215862274,\n",
       " 0.25098246335983276,\n",
       " 0.9676477313041687,\n",
       " 0.1701187789440155,\n",
       " 0.29049208760261536,\n",
       " 0.721258282661438,\n",
       " 0.3413147032260895,\n",
       " 0.9114903807640076,\n",
       " 0.7464573383331299,\n",
       " 0.3864081799983978,\n",
       " 0.2361128181219101,\n",
       " 0.6313906908035278,\n",
       " 0.05156971514225006,\n",
       " 0.9142124056816101,\n",
       " 0.33733487129211426,\n",
       " 0.8394294381141663,\n",
       " 0.3933698832988739,\n",
       " 0.603042721748352,\n",
       " 0.3046014606952667,\n",
       " 0.22371084988117218,\n",
       " 0.223710834980011,\n",
       " 0.8688709735870361,\n",
       " 0.08564148843288422,\n",
       " 0.9705791473388672,\n",
       " 0.0627020075917244,\n",
       " 0.9875437021255493,\n",
       " 0.6878703236579895,\n",
       " 0.19863064587116241,\n",
       " 0.33733487129211426,\n",
       " 0.9062102437019348,\n",
       " 0.4186277687549591,\n",
       " 0.2308027297258377,\n",
       " 0.5063952803611755,\n",
       " 0.7065640687942505,\n",
       " 0.28439250588417053,\n",
       " 0.6637837290763855,\n",
       " 0.8464905619621277,\n",
       " 0.6600561738014221,\n",
       " 0.5637055039405823,\n",
       " 0.5556942224502563,\n",
       " 0.9267479181289673,\n",
       " 0.6554861664772034,\n",
       " 0.883291482925415,\n",
       " 0.40855082869529724,\n",
       " 0.6327500343322754,\n",
       " 0.8377293348312378,\n",
       " 0.10023243725299835,\n",
       " 0.18132635951042175,\n",
       " 0.13129259645938873,\n",
       " 0.11772067844867706,\n",
       " 0.9191632270812988,\n",
       " 0.10656572133302689,\n",
       " 0.8776922821998596,\n",
       " 0.9155924916267395,\n",
       " 0.08958915621042252,\n",
       " 0.13223674893379211,\n",
       " 0.3479834794998169,\n",
       " 0.816439151763916,\n",
       " 0.45912817120552063,\n",
       " 0.5742262601852417,\n",
       " 0.28821292519569397,\n",
       " 0.9449992179870605,\n",
       " 0.6749883890151978,\n",
       " 0.8600781559944153,\n",
       " 0.7702024579048157,\n",
       " 0.3016669452190399,\n",
       " 0.5333791971206665,\n",
       " 0.5421633124351501,\n",
       " 0.01842568628489971,\n",
       " 0.33981645107269287,\n",
       " 0.23071466386318207,\n",
       " 0.20015083253383636,\n",
       " 0.8011693358421326,\n",
       " 0.28211796283721924,\n",
       " 0.28211796283721924,\n",
       " 0.2910999357700348,\n",
       " 0.1589246690273285,\n",
       " 0.06132230907678604,\n",
       " 0.6208130717277527,\n",
       " 0.49683788418769836,\n",
       " 0.9155924916267395,\n",
       " 0.3451055586338043,\n",
       " 0.6775915026664734,\n",
       " 0.3988384008407593,\n",
       " 0.07367291301488876,\n",
       " 0.7431530952453613,\n",
       " 0.2422279566526413,\n",
       " 0.2678467631340027,\n",
       " 0.5185402631759644,\n",
       " 0.5866849422454834,\n",
       " 0.764917254447937,\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# premise = \"I first thought that I liked the movie, but upon second thought it was actually disappointing.\"\n",
    "# hypothesis = \"The movie was good.\"\n",
    "\n",
    "P = [\"transcript: {}\".format(t) for t in transcripts_text]\n",
    "H_pos = '\"The \\\"{}\\\" happened during the event described by the transcript.'\n",
    "H_past = '\"The \\\"{}\\\" happened before the event described by the transcript.'\n",
    "H_hypo = '\"The \\\"{}\\\" was mentioned, but didnt actually happened in the event described by the transcript.'\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "validations_preds_all = []\n",
    "print(len(P))\n",
    "for i in range(0, len(transcripts_text), batch_size):\n",
    "    print(f\"{i} ({i/len(P)*100:.1f}%)\")\n",
    "    \n",
    "    batch_P = P[i:i+batch_size]\n",
    "    batch_H = H[i:i+batch_size]\n",
    "    input = tokenizer(batch_P, batch_H, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    output = model(input[\"input_ids\"])\n",
    "    predictions = torch.softmax(output[\"logits\"], -1).tolist()\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    entailment_probs = [pred[0] for pred in predictions]\n",
    "    validations_preds_all.extend(entailment_probs)\n",
    "validations_preds_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = expr_df['Label'].tolist()\n",
    "y_pred = validations_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
    "threshold = 0.01\n",
    "y_pred_bin = [1 if p >= threshold else 0 for p in y_pred]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "ap = average_precision_score(y_true, y_pred_bin)\n",
    "\n",
    "# Create a DataFrame for each fold's metrics\n",
    "metrics_df = pd.DataFrame([{\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'ap': ap,\n",
    "}])\n",
    "display(metrics_df)\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_bin)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "disp.plot(ax=ax)\n",
    "plt.title(\"Confusion Matrix (Ratios)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
